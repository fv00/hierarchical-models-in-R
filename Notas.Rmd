---
title: "readme"
author: "Santiago Franco Valencia"
date: "14/9/2022"
output: github_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Summary of GLM and LM

Se resumen las funciones utilizadas en los capítulos 3, 4, 5 y 6 del
texto guía de modelos jerarquícos:

## Linear regression

![linear regression](https://i.stack.imgur.com/83Jog.png)

```{r}
data(cars)
cars.lm <- lm(dist ~ speed, data = cars)
summary(cars.lm)
new.dat <- data.frame(speed=30)
#Confidence intervals and predictions
predict(cars.lm, newdata = new.dat, interval = 'confidence', level = 0.95)
##See predict.lm() for more documentation
```

## Logistic regression

![Logit function](https://i.stack.imgur.com/WY61Z.png)

### functions

```{r}
logit <- function(x){
  return(log((x)/(1-x)))
}
inverse_logit <- function(x){
  return(exp(x)/(1+exp(x)))
}
```

### Fitting logistic regression models:

```{r}
formula = ""
#logit_model <- glm(formula = formula, family=binomial(link='logit'))
```

### Interpretation of logistic regression coeficients:

-   Constant term can be interpreted as the estimated probability when
    other variables has the value of 0. (The "Weight" of the constant
    term).

-   The pendient terms can be interpreted as the estimated probability
    per unit by deriving the predictor inside the linf formula.

### Graphic logistic regretion:

```{r}
#Graph logit func:
## Plot x and y values
#plot(x,y)
## Plot curve of the model using the formula
#curve()
```

## Generalized linear models

Allos the answer Y to be normal, binomial, poisson, negative-binomial,
gamma, and inverse gaussian.

The variable Y is not modeled insted the mu parameter of the variable Y
is modeled.

```{r}
#Adjust model
#glm(formula, data=data, family=linkfunction())
#Predict
#link = predict(nb1, type = "link"),
#fit = predict(nb1, type = "response"),
```

The link function allows to map the predictor variable values inside the
correct parameter of the distribution assumed for Y.

It is important to know that te parameter *family* of the glm package
allows to assume certain distribution for the Y variable.

## Notes about mixed models

### Tipos de variables en modelos mixtos

Respuesta Y

Convariables x1,..., xk: Cuantitativas o cualitativas

De agrupación g1,...,g2: Sólo cualitativas y cada gj debe ser una m.a de
los niveles existentes. Ejemplo: Persona, barrio, ciudad departamento

```{r}

```

### no pooling

### Complete pooling

### Multilevel modeling

## Notación para efectos aleatorios:

$b_0, b_1,...$ $\alpha_0, \alpha_1...$ $U_0, U_1,...$
$b_{0i}: \text{Intercepto aleatorio para grupo i}$
$\hat{b_{0i}}: \text{Intercepto aleatorio PREDICHO para grupo i}$

## ¿Cómo se reporta un modelo ajustado en un artículo científico?

### Modelo ajustado:

General:

$Y_{ij}\text{~}N(\hat{\mu_{ij}}, \hat{\sigma_{y}})$
$\hat{\mu_{ij}} = 2.2378 - 6.0264x_{ij} + \hat{b_{0i}}$
$\hat{\sigma_y} = 3.9352$ $b_0\text{~}N(0, 25.3690)$

Por grupo

Grupo 3:

$Y_{3j}\text{~}N(\hat{\mu_{3j}}, \hat{\sigma_{y}})$ \$\hat{\mu_{3j}} =
2.2378 + 19.88 - 6.0264x\_{ij} \$ $\hat{\sigma_y} = 3.9352$
$b_0\text{~}N(0, 25.3690)$

¿Cuál es el valor esperado de Y cuando x=4? $E(Y|x=4)\hat{=}-2$

## Paquete lme4

```{r}
library(lme4)
```

### Función lmer

La función lmer es la principal función del paquete lme4. Esta función
sirve para ajustar un modelo mixto y su estructura es la siguiente:

``` r
lmer(formula, data = NULL, REML = TRUE, control = lmerControl(),
     start = NULL, verbose = 0L, subset, weights, na.action,
     offset, contrasts = NULL, devFunOnly = FALSE, ...)
```

Datos incluído en el paquete lmer:

```{r}
head(sleepstudy)
```

```{r}
library(ggplot2)

ggplot(data = sleepstudy, aes(x = Days, y = Reaction, color = Subject)) +
  geom_point() +
  theme_bw() +
  facet_wrap(~ Subject) + 
  theme(legend.position = "none")
```

### Planteamiento de modelos con lmer

```{r}
fit <- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy)
```

```{r}
summary(fit)
```

### Efectos fijos y aleatorios:

Efectos fijos:

```{r}

```

Efectos aleatorios

```{r}

```

## Paquete nlme

```{r}
library(nlme)
```

### Ajuste con nlme

```{r}
fit_lme <- lme(fixed = Reaction ~ Days, random = ~ 1+ Days | Subject,  data = sleepstudy, method = "REML")
```

```{r}
summary(fit_lme)
```

```{r}
library(stargazer)
```

```{r, results='asis'}
stargazer(fit_lme, type = 'latex')
```

## Actividad en clase

``` r
ni <- 50
G <- &&&
nobs <- ni * &&&                      # Numero total de observaciones
grupo <- factor(rep(x=1:G, each=&&&)) # Para crear la variable grupal
obs <- rep(x=1:ni, times=G)           # Para identificar las obs por grupo
x <- runif(n=nobs, min=&&&, max=&&&)  # La covariable
b0 <- rnorm(n=G, mean=&&&, sd=&&&)    # El Intercepto aleatorio
b0 <- rep(x=b0, each=ni)              # El intercepto aleatorio pero repetido
media <- &&& - 6 * x + &&&            # La media
&&& <- rnorm(n=nobs, mean=media, sd=&&&) # La variable respuesta
datos <- data.frame(grupo, obs, b0, x, &&&) # Organizando el dataframe
```

```{r}
ni <- 50
G <- 10
nobs <- ni * G                      # Numero total de observaciones
grupo <- factor(rep(x=1:G, each=ni)) # Para crear la variable grupal
obs <- rep(x=1:ni, times=G)           # Para identificar las obs por grupo
x <- runif(n=nobs, min=-5, max=6)  # La covariable
b0 <- rnorm(n=G, mean=0, sd=1)    # El Intercepto aleatorio
b0 <- rep(x=b0, each=ni)              # El intercepto aleatorio pero repetido
media <- 4 - 6 * x + b0            # La media
y <- rnorm(n=nobs, mean=media, sd=4) # La variable respuesta
datos <- data.frame(grupo, obs, b0, x, y) # Organizando el dataframe
```

```{r}
library(ggplot2)
ggplot(datos, aes(x, y, color=grupo) ) + 
  geom_point() + 
  labs(colour="Grupo/Cluster")
```


## Cómo distinguir las componentes aleatorias de un modelo desde su fórmula?

### Pendiente aleatoria

```r

```

### Intercepto aleatorio

```{r}
library(merTools)
model1 <- lmer(mathach ~ 1 + (1|schid), REML=FALSE, data=hsb)
summary(model1)
```

Según este resumen se tiene que:

* $\hat{\sigma_y}^2 = 39.148$
* $\hat{\sigma_{b_0}}^2 = 8.553$

Para seleccionar este valor se tiene en cuenta que las estimaciones de las varianzas siempre tienen que ver con los efectos aleatorios, ya que la estructura del vector de parámetros es:

$\theta=(\beta_0, \beta_1,\sigma_y^2, \sigma_{b_1}^2,\sigma_{b_0b_1}$

* Los errores estándar no entran al vector de parámetros $\theta$.

* Cuando la varianza de un efecto es "grande" respecto a la varianza asociada a la variable respuesta se tienen indicios de que la variable asociada al efecto tiene un peso considerable sobre la variable respuesta.

**Intervalo de confianza**

```{r}
confint(model1)
```
```{r}
model2 <- lmer(mathach ~ 1 + female + ses + (1|schid), REML=FALSE, data=hsb)
summary(model2)
```


### Pendiente + intercepto aleatorio

```{r}

```

## Comparación de modelos mediante anova


***IMPORTANTE***: La prueba que se realiza es una razón de verosimilitud.

```{r}
anova(model1, model2)
```

$H_0$: El modelo 2 no representa una mejora en el ajuste respecto al modelo 1.
$H_1$: El modelo 2 representa una mejora en el ajuste respecto al modelo 2.

En otras palabras:

$H_0$: $(\beta_{ses}\text{ }\beta_{female}) = (0, 0)$
$H_0$: $(\beta_{ses}\text{ }\beta_{female}) \neq (0, 0)$

Términos más sencillos:

$H_0$: El SES y el sexo NO ayudan a explicar el puntaje en matemáticas de los estudiantes.
$H_0$: El puntaje SES o el sexo ayudan a explicar el puntaje en matemáticas de los estudiantes.

```{r}
sigma2b0 = 8.553
sigma2y = 39.148
Icc = sigma2b0/(sigma2y+sigma2b0)
Icc
```
```{r}
ICC(outcome='mathach', group='schid', data =hsb)
```
